20221209-025434
==== Generate pruning schema ====
2022-12-09 02:54:36.716 | INFO     | __main__:<module>:47 - Testing pruning [yolox-s] with ratio [0.6]
2022-12-09 02:54:36.787 | INFO     | __main__:<module>:47 - Testing pruning [yolox-s] with ratio [0.7]
2022-12-09 02:54:36.842 | INFO     | __main__:<module>:47 - Testing pruning [yolox-s] with ratio [0.8]
2022-12-09 02:54:36.896 | INFO     | __main__:<module>:47 - Testing pruning [yolox-s] with ratio [0.9]
==== Sparsity training ====
2022-12-09 02:54:38 | INFO     | yolox.core.trainer:141 - args: Namespace(batch_size=64, cache=True, ckpt=None, devices=1, dist_backend='nccl', dist_url=None, exp_file='exps/network_slim/yolox_s_slim_train.py', experiment_name='yolox_s_slim_sparsity_train', fp16=False, logger='tensorboard', machine_rank=0, name=None, num_machines=1, occupy=False, opts=['network_slim_sparsity_train_s', '0.0001'], resume=False, start_epoch=None)
2022-12-09 02:54:38 | INFO     | yolox.core.trainer:142 - exp value:
╒══════════════════════════════════════════╤════════════════════════════╕
│ keys                                     │ values                     │
╞══════════════════════════════════════════╪════════════════════════════╡
│ seed                                     │ None                       │
├──────────────────────────────────────────┼────────────────────────────┤
│ output_dir                               │ './YOLOX_outputs'          │
├──────────────────────────────────────────┼────────────────────────────┤
│ print_interval                           │ 10                         │
├──────────────────────────────────────────┼────────────────────────────┤
│ eval_interval                            │ 10                         │
├──────────────────────────────────────────┼────────────────────────────┤
│ num_classes                              │ 10                         │
├──────────────────────────────────────────┼────────────────────────────┤
│ depth                                    │ 0.33                       │
├──────────────────────────────────────────┼────────────────────────────┤
│ width                                    │ 0.5                        │
├──────────────────────────────────────────┼────────────────────────────┤
│ act                                      │ 'silu'                     │
├──────────────────────────────────────────┼────────────────────────────┤
│ data_num_workers                         │ 4                          │
├──────────────────────────────────────────┼────────────────────────────┤
│ input_size                               │ (640, 640)                 │
├──────────────────────────────────────────┼────────────────────────────┤
│ multiscale_range                         │ 5                          │
├──────────────────────────────────────────┼────────────────────────────┤
│ data_dir                                 │ '/local_datasets/VisDrone' │
├──────────────────────────────────────────┼────────────────────────────┤
│ train_ann                                │ 'train2017.json'           │
├──────────────────────────────────────────┼────────────────────────────┤
│ val_ann                                  │ 'val2017.json'             │
├──────────────────────────────────────────┼────────────────────────────┤
│ mosaic_prob                              │ 1.0                        │
├──────────────────────────────────────────┼────────────────────────────┤
│ mixup_prob                               │ 1.0                        │
├──────────────────────────────────────────┼────────────────────────────┤
│ hsv_prob                                 │ 1.0                        │
├──────────────────────────────────────────┼────────────────────────────┤
│ flip_prob                                │ 0.5                        │
├──────────────────────────────────────────┼────────────────────────────┤
│ degrees                                  │ 10.0                       │
├──────────────────────────────────────────┼────────────────────────────┤
│ translate                                │ 0.1                        │
├──────────────────────────────────────────┼────────────────────────────┤
│ mosaic_scale                             │ (0.1, 2)                   │
├──────────────────────────────────────────┼────────────────────────────┤
│ mixup_scale                              │ (0.5, 1.5)                 │
├──────────────────────────────────────────┼────────────────────────────┤
│ shear                                    │ 2.0                        │
├──────────────────────────────────────────┼────────────────────────────┤
│ enable_mixup                             │ True                       │
├──────────────────────────────────────────┼────────────────────────────┤
│ warmup_epochs                            │ 5                          │
├──────────────────────────────────────────┼────────────────────────────┤
│ max_epoch                                │ 300                        │
├──────────────────────────────────────────┼────────────────────────────┤
│ warmup_lr                                │ 0                          │
├──────────────────────────────────────────┼────────────────────────────┤
│ basic_lr_per_img                         │ 0.00015625                 │
├──────────────────────────────────────────┼────────────────────────────┤
│ scheduler                                │ 'yoloxwarmcos'             │
├──────────────────────────────────────────┼────────────────────────────┤
│ no_aug_epochs                            │ 15                         │
├──────────────────────────────────────────┼────────────────────────────┤
│ min_lr_ratio                             │ 0.05                       │
├──────────────────────────────────────────┼────────────────────────────┤
│ ema                                      │ True                       │
├──────────────────────────────────────────┼────────────────────────────┤
│ weight_decay                             │ 0.0005                     │
├──────────────────────────────────────────┼────────────────────────────┤
│ momentum                                 │ 0.9                        │
├──────────────────────────────────────────┼────────────────────────────┤
│ exp_name                                 │ 'yolox_s_slim_train'       │
├──────────────────────────────────────────┼────────────────────────────┤
│ network_slim_sparsity_train_enable       │ True                       │
├──────────────────────────────────────────┼────────────────────────────┤
│ network_slim_sparsity_train_s            │ 0.0001                     │
├──────────────────────────────────────────┼────────────────────────────┤
│ network_slim_sparsity_train_warmup_epoch │ 120                        │
├──────────────────────────────────────────┼────────────────────────────┤
│ run_network_slim                         │ False                      │
├──────────────────────────────────────────┼────────────────────────────┤
│ network_slim_schema                      │ ''                         │
├──────────────────────────────────────────┼────────────────────────────┤
│ network_slim_ratio                       │ 0.65                       │
├──────────────────────────────────────────┼────────────────────────────┤
│ test_size                                │ (640, 640)                 │
├──────────────────────────────────────────┼────────────────────────────┤
│ test_conf                                │ 0.01                       │
├──────────────────────────────────────────┼────────────────────────────┤
│ nmsthre                                  │ 0.65                       │
├──────────────────────────────────────────┼────────────────────────────┤
│ test_ann                                 │ 'test2017.json'            │
╘══════════════════════════════════════════╧════════════════════════════╛
2022-12-09 02:54:39 | INFO     | yolox.core.trainer:148 - Model Summary: Params: 8.94M, Gflops: 26.78
2022-12-09 02:54:39 | INFO     | yolox.data.datasets.coco:65 - loading annotations into memory...
2022-12-09 02:54:41 | INFO     | yolox.data.datasets.coco:65 - Done (t=1.60s)
2022-12-09 02:54:41 | INFO     | pycocotools.coco:86 - creating index...
2022-12-09 02:54:41 | INFO     | pycocotools.coco:86 - index created!
2022-12-09 02:54:51 | WARNING  | yolox.data.datasets.coco:90 - 
********************************************************************************
You are using cached images in RAM to accelerate training.
This requires large system RAM.
Make sure you have 200G+ RAM and 136G available disk space for training COCO.
********************************************************************************

2022-12-09 02:54:51 | WARNING  | yolox.data.datasets.coco:124 - You are using cached imgs! Make sure your dataset is not changed!!
Everytime the self.input_size is changed in your exp file, you need to delete
the cached data and re-generate them.

2022-12-09 02:54:51 | INFO     | yolox.data.datasets.coco:129 - Loading cached imgs...
2022-12-09 02:54:51 | INFO     | yolox.core.trainer:168 - init prefetcher, this might take one minute or less...
2022-12-09 02:54:55 | INFO     | yolox.data.datasets.coco:65 - loading annotations into memory...
2022-12-09 02:54:55 | INFO     | yolox.data.datasets.coco:65 - Done (t=0.10s)
2022-12-09 02:54:55 | INFO     | pycocotools.coco:86 - creating index...
2022-12-09 02:54:55 | INFO     | pycocotools.coco:86 - index created!
2022-12-09 02:54:56 | INFO     | yolox.core.trainer:196 - Training start...
2022-12-09 02:54:56 | INFO     | yolox.core.trainer:197 - 
YOLOX(
  (backbone): YOLOPAFPN(
    (backbone): CSPDarknet(
      (stem): Focus(
        (conv): BaseConv(
          (conv): Conv2d(12, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
      )
      (dark2): Sequential(
        (0): BaseConv(
          (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (1): CSPLayer(
          (conv1): BaseConv(
            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (conv2): BaseConv(
            (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (conv3): BaseConv(
            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (m): Sequential(
            (0): Bottleneck(
              (conv1): BaseConv(
                (conv): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
              (conv2): BaseConv(
                (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
            )
          )
        )
      )
      (dark3): Sequential(
        (0): BaseConv(
          (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (1): CSPLayer(
          (conv1): BaseConv(
            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (conv2): BaseConv(
            (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (conv3): BaseConv(
            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (m): Sequential(
            (0): Bottleneck(
              (conv1): BaseConv(
                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
              (conv2): BaseConv(
                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
            )
            (1): Bottleneck(
              (conv1): BaseConv(
                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
              (conv2): BaseConv(
                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
            )
            (2): Bottleneck(
              (conv1): BaseConv(
                (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
              (conv2): BaseConv(
                (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
            )
          )
        )
      )
      (dark4): Sequential(
        (0): BaseConv(
          (conv): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (1): CSPLayer(
          (conv1): BaseConv(
            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (conv2): BaseConv(
            (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (conv3): BaseConv(
            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (m): Sequential(
            (0): Bottleneck(
              (conv1): BaseConv(
                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
              (conv2): BaseConv(
                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
            )
            (1): Bottleneck(
              (conv1): BaseConv(
                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
              (conv2): BaseConv(
                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
            )
            (2): Bottleneck(
              (conv1): BaseConv(
                (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
              (conv2): BaseConv(
                (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
            )
          )
        )
      )
      (dark5): Sequential(
        (0): BaseConv(
          (conv): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (1): SPPBottleneck(
          (conv1): BaseConv(
            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (m): ModuleList(
            (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)
            (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)
            (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)
          )
          (conv2): BaseConv(
            (conv): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
        )
        (2): CSPLayer(
          (conv1): BaseConv(
            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (conv2): BaseConv(
            (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (conv3): BaseConv(
            (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (m): Sequential(
            (0): Bottleneck(
              (conv1): BaseConv(
                (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
              (conv2): BaseConv(
                (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
            )
          )
        )
      )
    )
    (upsample): Upsample(scale_factor=2.0, mode=nearest)
    (lateral_conv0): BaseConv(
      (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
      (act): SiLU(inplace=True)
    )
    (C3_p4): CSPLayer(
      (conv1): BaseConv(
        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (conv2): BaseConv(
        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (conv3): BaseConv(
        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (m): Sequential(
        (0): Bottleneck(
          (conv1): BaseConv(
            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (conv2): BaseConv(
            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
        )
      )
    )
    (reduce_conv1): BaseConv(
      (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
      (act): SiLU(inplace=True)
    )
    (C3_p3): CSPLayer(
      (conv1): BaseConv(
        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (conv2): BaseConv(
        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (conv3): BaseConv(
        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (m): Sequential(
        (0): Bottleneck(
          (conv1): BaseConv(
            (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (conv2): BaseConv(
            (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(64, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
        )
      )
    )
    (bu_conv2): BaseConv(
      (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
      (act): SiLU(inplace=True)
    )
    (C3_n3): CSPLayer(
      (conv1): BaseConv(
        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (conv2): BaseConv(
        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (conv3): BaseConv(
        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (m): Sequential(
        (0): Bottleneck(
          (conv1): BaseConv(
            (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (conv2): BaseConv(
            (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
        )
      )
    )
    (bu_conv1): BaseConv(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
      (act): SiLU(inplace=True)
    )
    (C3_n4): CSPLayer(
      (conv1): BaseConv(
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (conv2): BaseConv(
        (conv): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (conv3): BaseConv(
        (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(512, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (m): Sequential(
        (0): Bottleneck(
          (conv1): BaseConv(
            (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (conv2): BaseConv(
            (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(256, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
        )
      )
    )
  )
  (head): YOLOXHead(
    (cls_convs): ModuleList(
      (0): Sequential(
        (0): BaseConv(
          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (1): BaseConv(
          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
      )
      (1): Sequential(
        (0): BaseConv(
          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (1): BaseConv(
          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
      )
      (2): Sequential(
        (0): BaseConv(
          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (1): BaseConv(
          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
      )
    )
    (reg_convs): ModuleList(
      (0): Sequential(
        (0): BaseConv(
          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (1): BaseConv(
          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
      )
      (1): Sequential(
        (0): BaseConv(
          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (1): BaseConv(
          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
      )
      (2): Sequential(
        (0): BaseConv(
          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (1): BaseConv(
          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
      )
    )
    (cls_preds): ModuleList(
      (0): Conv2d(128, 10, kernel_size=(1, 1), stride=(1, 1))
      (1): Conv2d(128, 10, kernel_size=(1, 1), stride=(1, 1))
      (2): Conv2d(128, 10, kernel_size=(1, 1), stride=(1, 1))
    )
    (reg_preds): ModuleList(
      (0): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))
      (1): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))
      (2): Conv2d(128, 4, kernel_size=(1, 1), stride=(1, 1))
    )
    (obj_preds): ModuleList(
      (0): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
      (1): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
      (2): Conv2d(128, 1, kernel_size=(1, 1), stride=(1, 1))
    )
    (stems): ModuleList(
      (0): BaseConv(
        (conv): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (1): BaseConv(
        (conv): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (2): BaseConv(
        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
    )
    (l1_loss): L1Loss()
    (bcewithlog_loss): BCEWithLogitsLoss()
    (iou_loss): IOUloss()
  )
)
2022-12-09 02:54:56 | INFO     | yolox.core.trainer:207 - ---> start train epoch1
2022-12-09 02:55:01 | ERROR    | yolox.models.yolo_head:332 - OOM RuntimeError is raised due to the huge memory cost during label assignment.                            CPU mode is applied in this batch. If you want to avoid this issue,                            try to reduce the batch size or image size.
2022-12-09 02:55:01 | INFO     | yolox.core.trainer:202 - Training of experiment is done and the best AP is 0.00
2022-12-09 02:55:01 | ERROR    | yolox.core.launch:98 - An error has been caught in function 'launch', process 'MainProcess' (41944), thread 'MainThread' (140319662613696):
Traceback (most recent call last):

  File "tools/train.py", line 141, in <module>
    args=(exp, args),
          │    └ Namespace(batch_size=64, cache=True, ckpt=None, devices=1, dist_backend='nccl', dist_url=None, exp_file='exps/network_slim/yo...
          └ ╒══════════════════════════════════════════╤═════════════════════════════════════════════════════════════════════════════════...

> File "/data/happyhoo97/repos/YOLOX/yolox/core/launch.py", line 98, in launch
    main_func(*args)
    │          └ (╒══════════════════════════════════════════╤════════════════════════════════════════════════════════════════════════════════...
    └ <function main at 0x7f9eb6a2cd40>

  File "tools/train.py", line 118, in main
    trainer.train()
    │       └ <function Trainer.train at 0x7f9e03438680>
    └ <yolox.core.trainer.Trainer object at 0x7f9e02e50150>

  File "/data/happyhoo97/repos/YOLOX/yolox/core/trainer.py", line 77, in train
    self.train_in_epoch()
    │    └ <function Trainer.train_in_epoch at 0x7f9e02ef59e0>
    └ <yolox.core.trainer.Trainer object at 0x7f9e02e50150>

  File "/data/happyhoo97/repos/YOLOX/yolox/core/trainer.py", line 86, in train_in_epoch
    self.train_in_iter()
    │    └ <function Trainer.train_in_iter at 0x7f9e02f27cb0>
    └ <yolox.core.trainer.Trainer object at 0x7f9e02e50150>

  File "/data/happyhoo97/repos/YOLOX/yolox/core/trainer.py", line 92, in train_in_iter
    self.train_one_iter()
    │    └ <function Trainer.train_one_iter at 0x7f9e02f2eb90>
    └ <yolox.core.trainer.Trainer object at 0x7f9e02e50150>

  File "/data/happyhoo97/repos/YOLOX/yolox/core/trainer.py", line 111, in train_one_iter
    self.scaler.scale(loss).backward()
    │    │      │     └ tensor(11.6103, device='cuda:0', grad_fn=<AddBackward0>)
    │    │      └ <function GradScaler.scale at 0x7f9e142b4680>
    │    └ <torch.cuda.amp.grad_scaler.GradScaler object at 0x7f9e02e50390>
    └ <yolox.core.trainer.Trainer object at 0x7f9e02e50150>

  File "/data/happyhoo97/anaconda3/envs/yolox_env/lib/python3.7/site-packages/torch/_tensor.py", line 488, in backward
    self, gradient, retain_graph, create_graph, inputs=inputs
    │     │         │             │                    └ None
    │     │         │             └ False
    │     │         └ None
    │     └ None
    └ tensor(11.6103, device='cuda:0', grad_fn=<AddBackward0>)
  File "/data/happyhoo97/anaconda3/envs/yolox_env/lib/python3.7/site-packages/torch/autograd/__init__.py", line 199, in backward
    allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass

torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 32.00 MiB (GPU 0; 23.70 GiB total capacity; 23.20 GiB already allocated; 23.69 MiB free; 23.29 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
------------CPU Mode for This Batch-------------
==== Network Slimming ====
2022-12-09 02:55:06 | INFO     | yolox.core.trainer:141 - args: Namespace(batch_size=64, cache=True, ckpt='./YOLOX_outputs/yolox_s_slim_sparsity_train/latest_ckpt.pth', devices=1, dist_backend='nccl', dist_url=None, exp_file='exps/network_slim/yolox_s_slim.py', experiment_name='yolox_s_slim_fine_tuning', fp16=False, logger='tensorboard', machine_rank=0, name=None, num_machines=1, occupy=False, opts=['network_slim_ratio', '0.65'], resume=False, start_epoch=None)
2022-12-09 02:55:06 | INFO     | yolox.core.trainer:142 - exp value:
╒══════════════════════════════════════════╤══════════════════════════════════════════════════════════════════════╕
│ keys                                     │ values                                                               │
╞══════════════════════════════════════════╪══════════════════════════════════════════════════════════════════════╡
│ seed                                     │ None                                                                 │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ output_dir                               │ './YOLOX_outputs'                                                    │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ print_interval                           │ 10                                                                   │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ eval_interval                            │ 10                                                                   │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ num_classes                              │ 10                                                                   │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ depth                                    │ 0.33                                                                 │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ width                                    │ 0.5                                                                  │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ act                                      │ 'silu'                                                               │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ data_num_workers                         │ 4                                                                    │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ input_size                               │ (640, 640)                                                           │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ multiscale_range                         │ 5                                                                    │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ data_dir                                 │ '/local_datasets/VisDrone'                                           │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ train_ann                                │ 'train2017.json'                                                     │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ val_ann                                  │ 'val2017.json'                                                       │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ mosaic_prob                              │ 1.0                                                                  │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ mixup_prob                               │ 1.0                                                                  │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ hsv_prob                                 │ 1.0                                                                  │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ flip_prob                                │ 0.5                                                                  │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ degrees                                  │ 10.0                                                                 │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ translate                                │ 0.1                                                                  │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ mosaic_scale                             │ (0.1, 2)                                                             │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ mixup_scale                              │ (0.5, 1.5)                                                           │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ shear                                    │ 2.0                                                                  │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ enable_mixup                             │ True                                                                 │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ warmup_epochs                            │ 5                                                                    │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ max_epoch                                │ 50                                                                   │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ warmup_lr                                │ 0                                                                    │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ basic_lr_per_img                         │ 0.00015625                                                           │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ scheduler                                │ 'yoloxwarmcos'                                                       │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ no_aug_epochs                            │ 15                                                                   │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ min_lr_ratio                             │ 0.05                                                                 │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ ema                                      │ True                                                                 │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ weight_decay                             │ 0.0005                                                               │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ momentum                                 │ 0.9                                                                  │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ exp_name                                 │ 'yolox_s_slim'                                                       │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ network_slim_sparsity_train_enable       │ False                                                                │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ network_slim_sparsity_train_s            │ 0.0001                                                               │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ network_slim_sparsity_train_warmup_epoch │ 300                                                                  │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ run_network_slim                         │ True                                                                 │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ network_slim_schema                      │ '/data/happyhoo97/repos/YOLOX/exps/network_slim/yolox_s_schema.json' │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ network_slim_ratio                       │ 0.65                                                                 │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ test_size                                │ (640, 640)                                                           │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ test_conf                                │ 0.01                                                                 │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ nmsthre                                  │ 0.65                                                                 │
├──────────────────────────────────────────┼──────────────────────────────────────────────────────────────────────┤
│ test_ann                                 │ 'test2017.json'                                                      │
╘══════════════════════════════════════════╧══════════════════════════════════════════════════════════════════════╛
2022-12-09 02:55:06 | INFO     | yolox.core.trainer:148 - Model Summary: Params: 8.94M, Gflops: 26.78
2022-12-09 02:55:07 | INFO     | yolox.core.trainer:318 - loading checkpoint for fine tuning
2022-12-09 02:55:07 | INFO     | yolox.data.datasets.coco:65 - loading annotations into memory...
2022-12-09 02:55:09 | INFO     | yolox.data.datasets.coco:65 - Done (t=1.61s)
2022-12-09 02:55:09 | INFO     | pycocotools.coco:86 - creating index...
2022-12-09 02:55:09 | INFO     | pycocotools.coco:86 - index created!
2022-12-09 02:55:19 | WARNING  | yolox.data.datasets.coco:90 - 
********************************************************************************
You are using cached images in RAM to accelerate training.
This requires large system RAM.
Make sure you have 200G+ RAM and 136G available disk space for training COCO.
********************************************************************************

2022-12-09 02:55:19 | WARNING  | yolox.data.datasets.coco:124 - You are using cached imgs! Make sure your dataset is not changed!!
Everytime the self.input_size is changed in your exp file, you need to delete
the cached data and re-generate them.

2022-12-09 02:55:19 | INFO     | yolox.data.datasets.coco:129 - Loading cached imgs...
2022-12-09 02:55:19 | INFO     | yolox.core.trainer:168 - init prefetcher, this might take one minute or less...
2022-12-09 02:55:22 | INFO     | yolox.data.datasets.coco:65 - loading annotations into memory...
2022-12-09 02:55:23 | INFO     | yolox.data.datasets.coco:65 - Done (t=0.10s)
2022-12-09 02:55:23 | INFO     | pycocotools.coco:86 - creating index...
2022-12-09 02:55:23 | INFO     | pycocotools.coco:86 - index created!
2022-12-09 02:55:25 | INFO     | yolox.core.trainer:196 - Training start...
2022-12-09 02:55:25 | INFO     | yolox.core.trainer:197 - 
YOLOX(
  (backbone): YOLOPAFPN(
    (backbone): CSPDarknet(
      (stem): Focus(
        (conv): BaseConv(
          (conv): Conv2d(12, 13, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(13, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
      )
      (dark2): Sequential(
        (0): BaseConv(
          (conv): Conv2d(13, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (1): CSPLayer(
          (conv1): BaseConv(
            (conv): Conv2d(32, 23, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(23, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (conv2): BaseConv(
            (conv): Conv2d(32, 15, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(15, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (conv3): BaseConv(
            (conv): Conv2d(38, 35, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(35, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (m): Sequential(
            (0): Bottleneck(
              (conv1): BaseConv(
                (conv): Conv2d(23, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(16, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
              (conv2): BaseConv(
                (conv): Conv2d(16, 23, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(23, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
            )
          )
        )
      )
      (dark3): Sequential(
        (0): BaseConv(
          (conv): Conv2d(35, 67, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(67, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (1): CSPLayer(
          (conv1): BaseConv(
            (conv): Conv2d(67, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(58, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (conv2): BaseConv(
            (conv): Conv2d(67, 38, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(38, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (conv3): BaseConv(
            (conv): Conv2d(96, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (m): Sequential(
            (0): Bottleneck(
              (conv1): BaseConv(
                (conv): Conv2d(58, 33, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(33, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
              (conv2): BaseConv(
                (conv): Conv2d(33, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(58, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
            )
            (1): Bottleneck(
              (conv1): BaseConv(
                (conv): Conv2d(58, 29, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(29, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
              (conv2): BaseConv(
                (conv): Conv2d(29, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(58, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
            )
            (2): Bottleneck(
              (conv1): BaseConv(
                (conv): Conv2d(58, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(32, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
              (conv2): BaseConv(
                (conv): Conv2d(32, 58, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(58, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
            )
          )
        )
      )
      (dark4): Sequential(
        (0): BaseConv(
          (conv): Conv2d(72, 111, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(111, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (1): CSPLayer(
          (conv1): BaseConv(
            (conv): Conv2d(111, 108, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(108, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (conv2): BaseConv(
            (conv): Conv2d(111, 58, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(58, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (conv3): BaseConv(
            (conv): Conv2d(166, 111, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(111, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (m): Sequential(
            (0): Bottleneck(
              (conv1): BaseConv(
                (conv): Conv2d(108, 56, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(56, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
              (conv2): BaseConv(
                (conv): Conv2d(56, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(108, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
            )
            (1): Bottleneck(
              (conv1): BaseConv(
                (conv): Conv2d(108, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
              (conv2): BaseConv(
                (conv): Conv2d(48, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(108, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
            )
            (2): Bottleneck(
              (conv1): BaseConv(
                (conv): Conv2d(108, 45, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(45, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
              (conv2): BaseConv(
                (conv): Conv2d(45, 108, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(108, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
            )
          )
        )
      )
      (dark5): Sequential(
        (0): BaseConv(
          (conv): Conv2d(111, 169, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(169, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (1): SPPBottleneck(
          (conv1): BaseConv(
            (conv): Conv2d(169, 109, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(109, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (m): ModuleList(
            (0): MaxPool2d(kernel_size=5, stride=1, padding=2, dilation=1, ceil_mode=False)
            (1): MaxPool2d(kernel_size=9, stride=1, padding=4, dilation=1, ceil_mode=False)
            (2): MaxPool2d(kernel_size=13, stride=1, padding=6, dilation=1, ceil_mode=False)
          )
          (conv2): BaseConv(
            (conv): Conv2d(436, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(184, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
        )
        (2): CSPLayer(
          (conv1): BaseConv(
            (conv): Conv2d(184, 83, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(83, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (conv2): BaseConv(
            (conv): Conv2d(184, 93, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(93, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (conv3): BaseConv(
            (conv): Conv2d(182, 167, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(167, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (m): Sequential(
            (0): Bottleneck(
              (conv1): BaseConv(
                (conv): Conv2d(83, 84, kernel_size=(1, 1), stride=(1, 1), bias=False)
                (bn): BatchNorm2d(84, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
              (conv2): BaseConv(
                (conv): Conv2d(84, 89, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
                (bn): BatchNorm2d(89, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
                (act): SiLU(inplace=True)
              )
            )
          )
        )
      )
    )
    (upsample): Upsample(scale_factor=2.0, mode=nearest)
    (lateral_conv0): BaseConv(
      (conv): Conv2d(167, 85, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(85, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
      (act): SiLU(inplace=True)
    )
    (C3_p4): CSPLayer(
      (conv1): BaseConv(
        (conv): Conv2d(196, 54, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(54, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (conv2): BaseConv(
        (conv): Conv2d(196, 50, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(50, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (conv3): BaseConv(
        (conv): Conv2d(97, 107, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(107, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (m): Sequential(
        (0): Bottleneck(
          (conv1): BaseConv(
            (conv): Conv2d(54, 49, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(49, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (conv2): BaseConv(
            (conv): Conv2d(49, 47, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(47, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
        )
      )
    )
    (reduce_conv1): BaseConv(
      (conv): Conv2d(107, 45, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bn): BatchNorm2d(45, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
      (act): SiLU(inplace=True)
    )
    (C3_p3): CSPLayer(
      (conv1): BaseConv(
        (conv): Conv2d(117, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(28, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (conv2): BaseConv(
        (conv): Conv2d(117, 29, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(29, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (conv3): BaseConv(
        (conv): Conv2d(55, 50, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(50, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (m): Sequential(
        (0): Bottleneck(
          (conv1): BaseConv(
            (conv): Conv2d(28, 28, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(28, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (conv2): BaseConv(
            (conv): Conv2d(28, 26, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(26, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
        )
      )
    )
    (bu_conv2): BaseConv(
      (conv): Conv2d(50, 48, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
      (act): SiLU(inplace=True)
    )
    (C3_n3): CSPLayer(
      (conv1): BaseConv(
        (conv): Conv2d(93, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(48, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (conv2): BaseConv(
        (conv): Conv2d(93, 31, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(31, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (conv3): BaseConv(
        (conv): Conv2d(71, 76, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(76, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (m): Sequential(
        (0): Bottleneck(
          (conv1): BaseConv(
            (conv): Conv2d(48, 38, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(38, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (conv2): BaseConv(
            (conv): Conv2d(38, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
        )
      )
    )
    (bu_conv1): BaseConv(
      (conv): Conv2d(76, 38, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
      (bn): BatchNorm2d(38, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
      (act): SiLU(inplace=True)
    )
    (C3_n4): CSPLayer(
      (conv1): BaseConv(
        (conv): Conv2d(123, 34, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(34, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (conv2): BaseConv(
        (conv): Conv2d(123, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (conv3): BaseConv(
        (conv): Conv2d(48, 66, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(66, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (m): Sequential(
        (0): Bottleneck(
          (conv1): BaseConv(
            (conv): Conv2d(34, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)
            (bn): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
          (conv2): BaseConv(
            (conv): Conv2d(24, 24, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
            (bn): BatchNorm2d(24, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
            (act): SiLU(inplace=True)
          )
        )
      )
    )
  )
  (head): YOLOXHead(
    (cls_convs): ModuleList(
      (0): Sequential(
        (0): BaseConv(
          (conv): Conv2d(51, 52, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(52, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (1): BaseConv(
          (conv): Conv2d(52, 80, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(80, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
      )
      (1): Sequential(
        (0): BaseConv(
          (conv): Conv2d(47, 40, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(40, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (1): BaseConv(
          (conv): Conv2d(40, 93, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(93, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
      )
      (2): Sequential(
        (0): BaseConv(
          (conv): Conv2d(33, 27, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(27, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (1): BaseConv(
          (conv): Conv2d(27, 56, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(56, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
      )
    )
    (reg_convs): ModuleList(
      (0): Sequential(
        (0): BaseConv(
          (conv): Conv2d(51, 51, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(51, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (1): BaseConv(
          (conv): Conv2d(51, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(72, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
      )
      (1): Sequential(
        (0): BaseConv(
          (conv): Conv2d(47, 43, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(43, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (1): BaseConv(
          (conv): Conv2d(43, 84, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(84, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
      )
      (2): Sequential(
        (0): BaseConv(
          (conv): Conv2d(33, 34, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(34, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
        (1): BaseConv(
          (conv): Conv2d(34, 66, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)
          (bn): BatchNorm2d(66, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
          (act): SiLU(inplace=True)
        )
      )
    )
    (cls_preds): ModuleList(
      (0): Conv2d(80, 10, kernel_size=(1, 1), stride=(1, 1))
      (1): Conv2d(93, 10, kernel_size=(1, 1), stride=(1, 1))
      (2): Conv2d(56, 10, kernel_size=(1, 1), stride=(1, 1))
    )
    (reg_preds): ModuleList(
      (0): Conv2d(72, 4, kernel_size=(1, 1), stride=(1, 1))
      (1): Conv2d(84, 4, kernel_size=(1, 1), stride=(1, 1))
      (2): Conv2d(66, 4, kernel_size=(1, 1), stride=(1, 1))
    )
    (obj_preds): ModuleList(
      (0): Conv2d(72, 1, kernel_size=(1, 1), stride=(1, 1))
      (1): Conv2d(84, 1, kernel_size=(1, 1), stride=(1, 1))
      (2): Conv2d(66, 1, kernel_size=(1, 1), stride=(1, 1))
    )
    (stems): ModuleList(
      (0): BaseConv(
        (conv): Conv2d(50, 51, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(51, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (1): BaseConv(
        (conv): Conv2d(76, 47, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(47, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
      (2): BaseConv(
        (conv): Conv2d(66, 33, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(33, eps=0.001, momentum=0.03, affine=True, track_running_stats=True)
        (act): SiLU(inplace=True)
      )
    )
    (l1_loss): L1Loss()
    (bcewithlog_loss): BCEWithLogitsLoss()
    (iou_loss): IOUloss()
  )
)
2022-12-09 02:55:25 | INFO     | yolox.core.trainer:207 - ---> start train epoch1
2022-12-09 02:55:39 | INFO     | yolox.core.trainer:274 - epoch: 1/50, iter: 10/102, mem: 12649Mb, iter_time: 1.408s, data_time: 0.048s, total_loss: 10.8, iou_loss: 4.4, l1_loss: 0.0, conf_loss: 5.2, cls_loss: 1.2, lr: 3.845e-06, size: 640, ETA: 1:59:29
2022-12-09 02:55:53 | INFO     | yolox.core.trainer:274 - epoch: 1/50, iter: 20/102, mem: 19069Mb, iter_time: 1.412s, data_time: 0.006s, total_loss: 11.3, iou_loss: 4.3, l1_loss: 0.0, conf_loss: 5.6, cls_loss: 1.3, lr: 1.538e-05, size: 800, ETA: 1:59:23
2022-12-09 02:56:04 | INFO     | yolox.core.trainer:274 - epoch: 1/50, iter: 30/102, mem: 19069Mb, iter_time: 1.063s, data_time: 0.005s, total_loss: 10.7, iou_loss: 4.4, l1_loss: 0.0, conf_loss: 5.2, cls_loss: 1.2, lr: 3.460e-05, size: 576, ETA: 1:49:21
2022-12-09 02:56:16 | INFO     | yolox.core.trainer:274 - epoch: 1/50, iter: 40/102, mem: 19069Mb, iter_time: 1.202s, data_time: 0.005s, total_loss: 10.8, iou_loss: 4.3, l1_loss: 0.0, conf_loss: 5.2, cls_loss: 1.3, lr: 6.151e-05, size: 672, ETA: 1:47:11
2022-12-09 02:56:28 | INFO     | yolox.core.trainer:274 - epoch: 1/50, iter: 50/102, mem: 19069Mb, iter_time: 1.219s, data_time: 0.005s, total_loss: 11.0, iou_loss: 4.2, l1_loss: 0.0, conf_loss: 5.3, cls_loss: 1.4, lr: 9.612e-05, size: 704, ETA: 1:46:06
2022-12-09 02:56:35 | INFO     | yolox.core.trainer:274 - epoch: 1/50, iter: 60/102, mem: 19069Mb, iter_time: 0.737s, data_time: 0.005s, total_loss: 10.8, iou_loss: 4.2, l1_loss: 0.0, conf_loss: 5.1, cls_loss: 1.4, lr: 1.384e-04, size: 672, ETA: 1:38:34
2022-12-09 02:56:44 | INFO     | yolox.core.trainer:274 - epoch: 1/50, iter: 70/102, mem: 19069Mb, iter_time: 0.843s, data_time: 0.005s, total_loss: 11.2, iou_loss: 4.2, l1_loss: 0.0, conf_loss: 5.6, cls_loss: 1.5, lr: 1.884e-04, size: 800, ETA: 1:34:24
2022-12-09 02:56:51 | INFO     | yolox.core.trainer:274 - epoch: 1/50, iter: 80/102, mem: 19069Mb, iter_time: 0.711s, data_time: 0.005s, total_loss: 10.6, iou_loss: 4.3, l1_loss: 0.0, conf_loss: 5.1, cls_loss: 1.3, lr: 2.461e-04, size: 640, ETA: 1:29:52
2022-12-09 02:56:59 | INFO     | yolox.core.trainer:274 - epoch: 1/50, iter: 90/102, mem: 19069Mb, iter_time: 0.789s, data_time: 0.004s, total_loss: 10.8, iou_loss: 4.3, l1_loss: 0.0, conf_loss: 5.2, cls_loss: 1.3, lr: 3.114e-04, size: 704, ETA: 1:27:03
2022-12-09 02:57:08 | INFO     | yolox.core.trainer:274 - epoch: 1/50, iter: 100/102, mem: 19069Mb, iter_time: 0.944s, data_time: 0.006s, total_loss: 10.4, iou_loss: 4.4, l1_loss: 0.0, conf_loss: 4.8, cls_loss: 1.2, lr: 3.845e-04, size: 512, ETA: 1:26:03
2022-12-09 02:57:10 | INFO     | yolox.core.trainer:356 - Save weights to ./YOLOX_outputs/yolox_s_slim_fine_tuning
2022-12-09 02:57:10 | INFO     | yolox.core.trainer:207 - ---> start train epoch2
2022-12-09 02:57:17 | INFO     | yolox.core.trainer:274 - epoch: 2/50, iter: 10/102, mem: 19069Mb, iter_time: 0.691s, data_time: 0.005s, total_loss: 10.8, iou_loss: 4.2, l1_loss: 0.0, conf_loss: 5.2, cls_loss: 1.4, lr: 4.823e-04, size: 704, ETA: 1:22:50
2022-12-09 02:57:24 | INFO     | yolox.core.trainer:274 - epoch: 2/50, iter: 20/102, mem: 19069Mb, iter_time: 0.743s, data_time: 0.004s, total_loss: 10.9, iou_loss: 4.3, l1_loss: 0.0, conf_loss: 5.4, cls_loss: 1.3, lr: 5.722e-04, size: 672, ETA: 1:20:57
2022-12-09 02:57:36 | INFO     | yolox.core.trainer:274 - epoch: 2/50, iter: 30/102, mem: 19069Mb, iter_time: 1.251s, data_time: 0.005s, total_loss: 10.8, iou_loss: 4.2, l1_loss: 0.0, conf_loss: 5.3, cls_loss: 1.4, lr: 6.699e-04, size: 768, ETA: 1:22:31
2022-12-09 02:57:50 | INFO     | yolox.core.trainer:274 - epoch: 2/50, iter: 40/102, mem: 19069Mb, iter_time: 1.309s, data_time: 0.005s, total_loss: 10.7, iou_loss: 4.1, l1_loss: 0.0, conf_loss: 5.2, cls_loss: 1.4, lr: 7.752e-04, size: 736, ETA: 1:24:10
2022-12-09 02:57:57 | INFO     | yolox.core.trainer:274 - epoch: 2/50, iter: 50/102, mem: 19069Mb, iter_time: 0.744s, data_time: 0.005s, total_loss: 10.7, iou_loss: 4.2, l1_loss: 0.0, conf_loss: 5.2, cls_loss: 1.3, lr: 8.883e-04, size: 672, ETA: 1:22:30
2022-12-09 02:58:04 | INFO     | yolox.core.trainer:274 - epoch: 2/50, iter: 60/102, mem: 19069Mb, iter_time: 0.720s, data_time: 0.005s, total_loss: 10.3, iou_loss: 4.3, l1_loss: 0.0, conf_loss: 4.8, cls_loss: 1.2, lr: 1.009e-03, size: 512, ETA: 1:20:55
2022-12-09 02:58:11 | INFO     | yolox.core.trainer:274 - epoch: 2/50, iter: 70/102, mem: 19069Mb, iter_time: 0.693s, data_time: 0.006s, total_loss: 10.9, iou_loss: 4.2, l1_loss: 0.0, conf_loss: 5.4, cls_loss: 1.4, lr: 1.137e-03, size: 800, ETA: 1:19:22
2022-12-09 02:58:20 | INFO     | yolox.core.trainer:274 - epoch: 2/50, iter: 80/102, mem: 19069Mb, iter_time: 0.853s, data_time: 0.006s, total_loss: 10.8, iou_loss: 4.2, l1_loss: 0.0, conf_loss: 5.3, cls_loss: 1.3, lr: 1.274e-03, size: 800, ETA: 1:18:41
slurmstepd: error: *** JOB 2847 ON sw9 CANCELLED AT 2022-12-09T02:58:23 ***
